library("ripa", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages("EBImage")
install.packages("tcltk")
install.packages("tcltk2")
library("tcltk", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("tcltk2", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages("ripa")
library("ripa")
source("http://bioconductor.org/biocLite.R")biocLite("EBImage", ask = FALSE)
library(tcltk)
BikeTheftLog <- read.csv("~/Documents/School/Data Science/kaggle/BikeTheftLog.csv")
View(BikeTheftLog)
#Worst Location seems to be swig, though with the method I used I had a hard time making sure every place is represented
BikeTheftLog$NewLoc <- "Blank"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Swig")] <- "Swig"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Dunne")] <- "Dunne"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Nobili")] <- "Nobili"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "McLaughlin")] <- "McLaughlin"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Casa")] <- "Casa"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Graham")] <- "Graham"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Benson")] <- "Benson"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Campisi")] <- "Campisi"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Sobrato")] <- "Sobrato"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Kenna")] <- "Kenna"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Bannan")] <- "Bannan"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Engineering")] <- "Engineering"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Malley")] <- "Malley"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Music")] <- "Music"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "O'Connor")] <- "O'Connor"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Walsh")] <- "Walsh"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Villas")] <- "Villas"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Sanfilippo")] <- "Sanfilippo"
#Worst Day of week turns out to be Monday
BikeTheftLog$DATE <- as.Date(BikeTheftLog$DATE, "%m/%d/%y")
BikeTheftLog$DayOfWeek <- weekdays(as.Date(BikeTheftLog$DATE))
WorstDayOfWeek <- table(BikeTheftLog$DayOfWeek)
sort(WorstDayOfWeek, decreasing = TRUE)
#Worst month of the year turns out to be Februrary
BikeTheftLog$MonthOfYear <- months(as.Date(BikeTheftLog$DATE))
WorstMonthOfYear <- table(BikeTheftLog$MonthOfYear)
sort(WorstMonthOfYear, decreasing = TRUE)
View(BikeTheftLog)
View(BikeTheftLog)
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Swig")] <- "Swig"
library("stringi", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("stringr", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Swig")] <- "Swig"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Dunne")] <- "Dunne"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Nobili")] <- "Nobili"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "McLaughlin")] <- "McLaughlin"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Casa")] <- "Casa"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Graham")] <- "Graham"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Benson")] <- "Benson"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Campisi")] <- "Campisi"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Sobrato")] <- "Sobrato"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Kenna")] <- "Kenna"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Bannan")] <- "Bannan"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Engineering")] <- "Engineering"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Malley")] <- "Malley"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Music")] <- "Music"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "O'Connor")] <- "O'Connor"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Walsh")] <- "Walsh"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Villas")] <- "Villas"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Sanfilippo")] <- "Sanfilippo"
View(BikeTheftLog)
View(BikeTheftLog)
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Blank")] <- "Other"
View(BikeTheftLog)
View(BikeTheftLog)
BikeTheftLog$NewLoc <- "Other"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Swig")] <- "Swig"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Dunne")] <- "Dunne"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Nobili")] <- "Nobili"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "McLaughlin")] <- "McLaughlin"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Casa")] <- "Casa"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Graham")] <- "Graham"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Benson")] <- "Benson"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Campisi")] <- "Campisi"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Sobrato")] <- "Sobrato"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Kenna")] <- "Kenna"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Bannan")] <- "Bannan"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Engineering")] <- "Engineering"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Malley")] <- "Malley"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Music")] <- "Music"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "O'Connor")] <- "O'Connor"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Walsh")] <- "Walsh"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Villas")] <- "Villas"
BikeTheftLog$NewLoc[str_detect(BikeTheftLog$LOCATION, "Sanfilippo")] <- "Sanfilippo"
View(BikeTheftLog)
View(BikeTheftLog)
unemployment <- read.delim("~/Desktop/inclass_d3_assignment/unemployment.tsv")
View(unemployment)
WorstDayOfWeek <- table(BikeTheftLog$DayOfWeek)
sort(WorstDayOfWeek, decreasing = TRUE)
BikeTheftLog$MonthOfYear <- months(as.Date(BikeTheftLog$DATE))
WorstMonthOfYear <- table(BikeTheftLog$MonthOfYear)
sort(WorstMonthOfYear, decreasing = TRUE)
bikelog2 <- data.from("location" = BikeTheftLog$NewLoc)
table(BikeTheftLog$NewLoc, BikeTheftLog$MonthOfYear)
bikelog 2 <- table(BikeTheftLog$NewLoc, BikeTheftLog$MonthOfYear)
help(write.csv)
write.table(BikeTheftLog$NewLoc, BikeTheftLog$MonthOfYear)
table(BikeTheftLog$NewLoc, BikeTheftLog$MonthOfYear)
as.dataframe(BikeTheftLog$NewLoc, BikeTheftLog$MonthOfYear)
as.data.frame(BikeTheftLog$NewLoc, BikeTheftLog$MonthOfYear)
as.data.frame(BikeTheftLog$LOCATION, BikeTheftLog$MonthOfYear)
as.data.frame(BikeTheftLog$NewLoc, BikeTheftLog$MonthOfYear)
table(BikeTheftLog$NewLoc, BikeTheftLog$MonthOfYear)
help(as.data.frame)
write.csv(table(BikeTheftLog$NewLoc, BikeTheftLog$MonthOfYear))
bikelogtest <- read.csv("~/Desktop/bikelogtest.csv")
View(bikelogtest)
write.table(test, file='test.tsv', quote=FALSE, sep='\t', col.names = NA)
write.table(bikelogtest, file='test.tsv', quote=FALSE, sep='\t', col.names = NA)
View(bikelogtest)
write.table(bikelogtest2, file='test.tsv', quote=FALSE, sep='\t')
write.table(bikelogtest, file='biketest.tsv', quote=FALSE, sep='\t')
biketest <- read.delim("~/biketest.tsv")
View(biketest)
biketest <- read.delim("~/biketest.tsv")
View(biketest)
biketest3 <- read.csv("~/Desktop/biketest3.csv")
View(biketest3)
write.table(bikelogtest3, file='biketest3.tsv', quote=FALSE, sep='\t')
write.table(biketest3, file='biketest3.tsv', quote=FALSE, sep='\t')
write.table(biketest3, file='biketest3.tsv', quote=FALSE, sep='\t', row.names = FALE)
write.table(biketest3, file='biketest3.tsv', quote=FALSE, sep='\t', row.names = FALSE)
install.packages("zoo")
load("~/Documents/School/Data Science/kaggle/notmine.R")
load("~/Documents/School/Data Science/kaggle/notmine.R")
load("~/Documents/School/Data Science/kaggle/notmine.R")
load("~/Documents/School/Data Science/kaggle/Titanic2.R")
load("~/Documents/School/Data Science/kaggle/TitanicProject.R")
help(data.frame)
GSS <- read.csv("~/Desktop/GSS.csv")
View(GSS)
install.packages("foreign")
help(setwd)
getwd()
setwd(~/Desktop/CSCI 183 Ordered/Homework/HW 3 538 Contingency)
setwd('~/Desktop/CSCI 183 Ordered/Homework/HW 3 538 Contingency')
read.spss(GSS2014.sav)
library("foreign", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
read.spss(GSS2014.sav)
read.spss(GSS2014)
gss <- read.csv('GSS.csv')
install.packages("haven")
install.packages("vcd")
library("vcd", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("haven", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
GSS2010 <- read_dta('GSS2010.dta')
help(read_dta)
help(labeling_cells)
help(mosaic)
advanced_pitcher <- read.csv("~/Documents/Personal Projects/Baseball/advanced_pitcher.csv")
View(advanced_pitcher)
batting_advstats <- read.csv("~/Documents/Personal Projects/Baseball/batting_advstats.csv")
View(batting_advstats)
batting_stats <- read.csv("~/Documents/Personal Projects/Baseball/batting_stats.csv")
View(batting_stats)
setwd('~/Documents/Personal Projects/Baseball/')
batting_stats$Fantasy_Points <- ((baseball_stats$HR)*4)
batting_stats$Fantasy_Points <- ((batting_stats$HR)*4)
View(batting_stats)
batting_stats$X1B <- (batting_stats$H - batting_stats$X2B - batting_stats$X3B - batting_stats$HR)
View(batting_stats)
batting_stats$Fantasy_Points <- ((batting_stats$HR)*4+batting_stats$X1B+batting_stats$X2B*2+batting_stats$X3B*3+batting_stats$RBI+batting_stats$SB+batting_stats$HBP+batting_stats$BB+batting_stats$R-(batting_stats$AB-batting_stats$H))
View(batting_stats)
batting_stats$Fantasy_Points <- ((batting_stats$HR)*4+batting_stats$X1B+batting_stats$X2B*2+batting_stats$X3B*3+batting_stats$RBI+batting_stats$SB+batting_stats$HBP+batting_stats$BB+batting_stats$R
View(batting_advstats)
View(advanced_pitcher)
View(batting_stats)
View(batting_stats)
batting_stats$Fantasy_Points <- ((batting_stats$HR)*4
View(batting_stats)
batting_stats$Fantasy_Points <- ((batting_stats$HR*4)+(batting_stats$X1B)+(batting_stats$X2B*2)+(batting_stats$X3B*3)+(batting_stats$RBI)+(batting_stats$SB)+(batting_stats$HBP)+(batting_stats$BB)+(batting_stats$R)-(batting_stats$AB-batting_stats$H))
View(batting_stats)
batting_stats$Fantasy_Points <- ((batting_stats$HR*4)+(batting_stats$X1B)+(batting_stats$X2B*2)+(batting_stats$X3B*3)+(batting_stats$RBI)+(batting_stats$SB)+(batting_stats$HBP)+(batting_stats$BB)+(batting_stats$R)-(batting_stats$AB-batting_stats$H)*.25)
View(batting_stats)
batting_stats$FPPG <- batting_stats$Fantasy_Points/batting_stats$G
View(batting_stats)
qplot(batting_stats$Fantasy_Points,batting_stats$FPPG)
library(ggplot2)
plot(batting_stats$Fantasy_Points,batting_stats$FPPG)
qplot(batting_stats$Fantasy_Points,batting_stats$FPPG)
qplot(batting_stats$Fantasy_Points,batting_stats$FPPG,x =Fantasy_Points, y = Fantasy Points Per Game)
qplot(Fantasy_Points,FPPG,data = batting_stats, colour = cyl)
qplot(Fantasy_Points,FPPG,data = batting_stats, colour = red)
qplot(Fantasy_Points,FPPG,data = batting_stats)
batting_stats <- read.csv("~/Documents/Personal Projects/Baseball/batting_stats.csv")
View(batting_stats)
batting_stats$X1B <- (batting_stats$H - batting_stats$X2B - batting_stats$X3B - batting_stats$HR) #Singles
#below is the total fantasy points in a game judged by Fan Duel's scoring system for batters
batting_stats$Fantasy_Points <- ((batting_stats$HR*4)+(batting_stats$X1B)+(batting_stats$X2B*2)+(batting_stats$X3B*3)+(batting_stats$RBI)+(batting_stats$SB)+(batting_stats$HBP)+(batting_stats$BB)+(batting_stats$R)-(batting_stats$AB-batting_stats$H)*.25)
batting_stats$FPPG <- batting_stats$Fantasy_Points/batting_stats$G #Fantasy Points Per a Game
library(ggplot2)
plot(batting_stats$Fantasy_Points,batting_stats$FPPG)
qplot(Fantasy_Points,FPPG,data = batting_stats)
View(batting_stats)
qplot(Fantasy_Points,FPPG,data = batting_stats, x = 'Total Fantas Points', y = 'Fantasy Points Per Game')
plot(Fantasy_Points,FPPG,data = batting_stats, x = 'Total Fantas Points', y = 'Fantasy Points Per Game')
help(qplot)
qplot(Fantasy_Points,FPPG,data = batting_stats, xlab = 'Total Fantas Points', ylab = 'Fantasy Points Per Game')
qplot(Fantasy_Points,FPPG,data = batting_stats, xlab = 'Total Fantasy Points', ylab = 'Fantasy Points Per Game')
setwd('~/Desktop/ThirdKaggle')
library(readr)
library(nnet)
install.packages("readr")
library(readr)
train <- read_csv("train.csv")
test <- read_csv("test.csv")
predictions<-data.frame('C1'=NA, 'C2'=NA,'C3'=NA,'C4'=NA,'C5'=NA,'C6'=NA,'C7'=NA,'C8'=NA,'C9'=NA,'C0'=NA,Imageid=1:nrow(test),Label=NA)
inTrain=sample(1:nrow(train),1000)
label <- as.factor(train[inTrain,1])
train<-train[inTrain,-1]
mod1<-glm((label==1)~.,data=train,family=binomial(link=logit))
mod2<-glm((label==2)~.,data=train,family=binomial(link=logit))
mod3<-glm((label==3)~.,data=train,family=binomial(link=logit))
mod4<-glm((label==4)~.,data=train,family=binomial(link=logit))
mod5<-glm((label==5)~.,data=train,family=binomial(link=logit))
mod6<-glm((label==6)~.,data=train,family=binomial(link=logit))
mod7<-glm((label==7)~.,data=train,family=binomial(link=logit))
mod8<-glm((label==8)~.,data=train,family=binomial(link=logit))
mod9<-glm((label==9)~.,data=train,family=binomial(link=logit))
mod0<-glm((label==0)~.,data=train,family=binomial(link=logit))
predictions[,2]<-predict(mod1,test,type='response')
predictions[,3]<-predict(mod2,test,type='response')
predictions[,4]<-predict(mod3,test,type='response')
predictions[,5]<-predict(mod4,test,type='response')
predictions[,6]<-predict(mod5,test,type='response')
predictions[,7]<-predict(mod6,test,type='response')
predictions[,8]<-predict(mod7,test,type='response')
predictions[,9]<-predict(mod8,test,type='response')
predictions[,10]<-predict(mod9,test,type='response')
predictions[,1]<-predict(mod0,test,type='response')
predictions[,12]<-apply(predictions[,1:10],1,which.max)
predictions[,12]<-predictions[,12]-1
write_csv(predictions[,11:12], "testsub.csv")
library(randomForest)
library(readr)
set.seed(0)
numTrain <- 10000
numTrees <- 25
train <- read_csv("train.csv")
test <- read_csv("test.csv")
rows <- sample(1:nrow(train), numTrain)
labels <- as.factor(train[rows,1])
train <- train[rows,-1]
rf <- randomForest(train, labels, xtest=test, ntree=numTrees)
predictions <- data.frame(ImageId=1:nrow(test), Label=levels(labels)[rf$test$predicted])
head(predictions)
write_csv(predictions, "rf_benchmark.csv")
set.seed(0)
library(randomForest)
library(ggplot2)
library(MASS)
library(data.table)
install.packages("randomForest")
# Creates a simple random forest benchmark
library(randomForest)
library(readr)
set.seed(0)
numTrain <- 10000
numTrees <- 25
train <- read_csv("../input/train.csv")
test <- read_csv("../input/test.csv")
rows <- sample(1:nrow(train), numTrain)
labels <- as.factor(train[rows,1])
train <- train[rows,-1]
rf <- randomForest(train, labels, xtest=test, ntree=numTrees)
predictions <- data.frame(ImageId=1:nrow(test), Label=levels(labels)[rf$test$predicted])
head(predictions)
write_csv(predictions, "randomforestsecond")
library(randomForest)
library(readr)
set.seed(0)
numTrain <- 10000
numTrees <- 25
train <- read_csv("test.csv")
test <- read_csv("train.csv")
rows <- sample(1:nrow(train), numTrain)
labels <- as.factor(train[rows,1])
train <- train[rows,-1]
rf <- randomForest(train, labels, xtest=test, ntree=numTrees)
predictions <- data.frame(ImageId=1:nrow(test), Label=levels(labels)[rf$test$predicted])
head(predictions)
install.packages("xgboost")
write_csv(predictions, "randomforestsecond2")
Creates a simple random forest benchmark
library(randomForest)
library(readr)
set.seed(0)
numTrain <- 10000
numTrees <- 25
train <- read_csv("test.csv")
test <- read_csv("train.csv")
rows <- sample(1:nrow(train), numTrain)
labels <- as.factor(train[rows,1])
train <- train[rows,-1]
rf <- randomForest(train, labels, xtest=test, ntree=numTrees)
predictions <- data.frame(ImageId=1:nrow(test), Label=levels(labels)[rf$test$predicted])
head(predictions)
write_csv(predictions, "randomforestsecond2")
# Using RandomForest proximity to visualize digits data set
# This script fits a random forest model, and uses "proximity" to visualize the results.
# Proximity between two examples is based on how often they are in a common leaf node.
# The examples are then embedded in R^2 using multidimensional scaling so as to make
# the Euclidean distances match the proximities from the RF.
# If you're looking for a nice embedding, there are better approaches (e.g. https://lvdmaaten.github.io/tsne/).
# I'm taking this one here since maybe it will provide some insight into what the RF is doing.
set.seed(0)
library(randomForest)
library(ggplot2)
library(MASS)
library(data.table)
numTrees <- 50
numRowsForModel <- 10000
numRowsForMDS <- 1000
numRowsToDrawAsImages <- 750
train <- data.frame(fread("train.csv", header=TRUE))
# Use only a subset of train to save time
smallTrain = train[sample(1:nrow(train), size = numRowsForModel),]
labels <- as.factor(smallTrain[[1]])
smallTrain = smallTrain[,-1]
# Make my own train/test split
inMyTrain = sample(c(TRUE,FALSE), size = numRowsForModel, replace = TRUE)
myTrain = smallTrain[inMyTrain,]
myTest = smallTrain[!inMyTrain,]
labelsMyTrain = labels[inMyTrain]
labelsMyTest = labels[!inMyTrain]
# Random forest (generates proximities)
rf <- randomForest(myTrain, labelsMyTrain, ntree = numTrees, xtest = myTest, proximity = TRUE)
predictions <- levels(labels)[rf$test$predicted]
predictionIsCorrect = labelsMyTest == predictions
cat(sprintf("Proportion correct in my test set: %f\n", mean(predictionIsCorrect)))
# Do MDS on subset (to save time) of proximities
# Get the portion of the proximity matrix just for my holdout set:
prox = rf$test$proximity[,1:nrow(myTest)]
# Get proximities just for a smaller subset:
proxSmall = prox[1:numRowsForMDS,1:numRowsForMDS]
cat("Beginnging MDS (embedding data in R^2, respecting the RF proximities as much as possible:\n")
embeddingSmall = isoMDS(1 - proxSmall, k = 2)
embeddedSubsetPredictions <- predictions[1:numRowsForMDS]
embeddedSubsetLabels <- labelsMyTest[1:numRowsForMDS]
embeddedSubsetPredictionIsCorrect <- predictionIsCorrect[1:numRowsForMDS]
makeAnnotationRaster <- function(rowNum, size, posDF,  imageDF, correct, digit, colors) {
row <- as.numeric(imageDF[rowNum,])
t   <- 1 - row/max(row)*0.8
rowHSV <- if (correct[rowNum]) {
#hsv((digit[rowNum]+1)/11, 0.4, 1.0, ifelse(t>0.8, 0.0, 0.8))
rgb(colors[digit[rowNum],"r"],colors[digit[rowNum],"g"],colors[digit[rowNum],"b"],ifelse(t>0.8, 0.0, 0.7))
} else {
hsv(0, 1.0, 1.0, ifelse(t>0.8, 0.0, 1.0))
}
rowMatrix <- matrix((rowHSV), 28, 28)
plotSize = ifelse(correct[rowNum], size, size*1.5)
pos <- c(posDF[rowNum,] - plotSize/2, posDF[rowNum,] + plotSize/2)
return(annotation_raster(t(rowMatrix), pos[1], pos[3], pos[2], pos[4]))
}
colors = data.frame(r=c(166, 31, 178, 51, 251, 227, 253, 255, 202, 106),
g=c(206, 120, 223, 160, 154, 26, 191, 127, 178, 61),
b=c(227, 180, 138, 44, 153, 28, 111, 0, 214, 154)) / 255
rowsForPlottingAsImages = sample(1:numRowsForMDS, numRowsToDrawAsImages)
ARs = Map(function(rows) makeAnnotationRaster(rows, .05, embeddingSmall$points, myTest, (predictions == labelsMyTest), as.numeric(labelsMyTest), colors),
rowsForPlottingAsImages)
p <- ggplot(data.frame(embeddingSmall$points), aes(x=X1, y=X2)) +
geom_blank() +
scale_shape_manual(values = c(17,16)) +
scale_size_manual(values = c(5,3)) +
labs(color = "True Label ", size="Correctly Classified ", shape="Correctly Classified ") +
theme_light(base_size=20) +
theme(strip.background = element_blank(),
strip.text.x     = element_blank(),
axis.text.x      = element_blank(),
axis.text.y      = element_blank(),
axis.ticks       = element_blank(),
axis.line        = element_blank(),
panel.border     = element_blank(),
legend.position  = "top") +
xlab("") + ylab("") +
ggtitle("2D MNIST Embedding Using RF Proximity\n(red highlights classification errors)")
png(filename = "digitsubtest.png", width = 960, height = 960)
Reduce("+", ARs, init = p)
install.packages("data.table")
library("data.table", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
# Using RandomForest proximity to visualize digits data set
# This script fits a random forest model, and uses "proximity" to visualize the results.
# Proximity between two examples is based on how often they are in a common leaf node.
# The examples are then embedded in R^2 using multidimensional scaling so as to make
# the Euclidean distances match the proximities from the RF.
# If you're looking for a nice embedding, there are better approaches (e.g. https://lvdmaaten.github.io/tsne/).
# I'm taking this one here since maybe it will provide some insight into what the RF is doing.
set.seed(0)
library(randomForest)
library(ggplot2)
library(MASS)
library(data.table)
numTrees <- 50
numRowsForModel <- 10000
numRowsForMDS <- 1000
numRowsToDrawAsImages <- 750
train <- data.frame(fread("train.csv", header=TRUE))
# Use only a subset of train to save time
smallTrain = train[sample(1:nrow(train), size = numRowsForModel),]
labels <- as.factor(smallTrain[[1]])
smallTrain = smallTrain[,-1]
# Make my own train/test split
inMyTrain = sample(c(TRUE,FALSE), size = numRowsForModel, replace = TRUE)
myTrain = smallTrain[inMyTrain,]
myTest = smallTrain[!inMyTrain,]
labelsMyTrain = labels[inMyTrain]
labelsMyTest = labels[!inMyTrain]
# Random forest (generates proximities)
rf <- randomForest(myTrain, labelsMyTrain, ntree = numTrees, xtest = myTest, proximity = TRUE)
predictions <- levels(labels)[rf$test$predicted]
predictionIsCorrect = labelsMyTest == predictions
cat(sprintf("Proportion correct in my test set: %f\n", mean(predictionIsCorrect)))
# Do MDS on subset (to save time) of proximities
# Get the portion of the proximity matrix just for my holdout set:
prox = rf$test$proximity[,1:nrow(myTest)]
# Get proximities just for a smaller subset:
proxSmall = prox[1:numRowsForMDS,1:numRowsForMDS]
cat("Beginnging MDS (embedding data in R^2, respecting the RF proximities as much as possible:\n")
embeddingSmall = isoMDS(1 - proxSmall, k = 2)
embeddedSubsetPredictions <- predictions[1:numRowsForMDS]
embeddedSubsetLabels <- labelsMyTest[1:numRowsForMDS]
embeddedSubsetPredictionIsCorrect <- predictionIsCorrect[1:numRowsForMDS]
makeAnnotationRaster <- function(rowNum, size, posDF,  imageDF, correct, digit, colors) {
row <- as.numeric(imageDF[rowNum,])
t   <- 1 - row/max(row)*0.8
rowHSV <- if (correct[rowNum]) {
#hsv((digit[rowNum]+1)/11, 0.4, 1.0, ifelse(t>0.8, 0.0, 0.8))
rgb(colors[digit[rowNum],"r"],colors[digit[rowNum],"g"],colors[digit[rowNum],"b"],ifelse(t>0.8, 0.0, 0.7))
} else {
hsv(0, 1.0, 1.0, ifelse(t>0.8, 0.0, 1.0))
}
rowMatrix <- matrix((rowHSV), 28, 28)
plotSize = ifelse(correct[rowNum], size, size*1.5)
pos <- c(posDF[rowNum,] - plotSize/2, posDF[rowNum,] + plotSize/2)
return(annotation_raster(t(rowMatrix), pos[1], pos[3], pos[2], pos[4]))
}
colors = data.frame(r=c(166, 31, 178, 51, 251, 227, 253, 255, 202, 106),
g=c(206, 120, 223, 160, 154, 26, 191, 127, 178, 61),
b=c(227, 180, 138, 44, 153, 28, 111, 0, 214, 154)) / 255
rowsForPlottingAsImages = sample(1:numRowsForMDS, numRowsToDrawAsImages)
ARs = Map(function(rows) makeAnnotationRaster(rows, .05, embeddingSmall$points, myTest, (predictions == labelsMyTest), as.numeric(labelsMyTest), colors),
rowsForPlottingAsImages)
p <- ggplot(data.frame(embeddingSmall$points), aes(x=X1, y=X2)) +
geom_blank() +
scale_shape_manual(values = c(17,16)) +
scale_size_manual(values = c(5,3)) +
labs(color = "True Label ", size="Correctly Classified ", shape="Correctly Classified ") +
theme_light(base_size=20) +
theme(strip.background = element_blank(),
strip.text.x     = element_blank(),
axis.text.x      = element_blank(),
axis.text.y      = element_blank(),
axis.ticks       = element_blank(),
axis.line        = element_blank(),
panel.border     = element_blank(),
legend.position  = "top") +
xlab("") + ylab("") +
ggtitle("2D MNIST Embedding Using RF Proximity\n(red highlights classification errors)")
png(filename = "digitsubtest.png", width = 960, height = 960)
Reduce("+", ARs, init = p)
invisible(dev.off())
# Creates a simple random forest benchmark
library(randomForest)
library(readr)
set.seed(0)
numTrain <- 10000
numTrees <- 50
train <- read_csv("test.csv")
test <- read_csv("train.csv")
rows <- sample(1:nrow(train), numTrain)
labels <- as.factor(train[rows,1])
train <- train[rows,-1]
rf <- randomForest(train, labels, xtest=test, ntree=numTrees)
predictions <- data.frame(ImageId=1:nrow(test), Label=levels(labels)[rf$test$predicted])
head(predictions)
write_csv(predictions, "randomforestsecond2")
# Creates a simple random forest benchmark
library(randomForest)
library(readr)
set.seed(0)
numTrain <- 10000
numTrees <- 50
train <- read_csv("test.csv")
test <- read_csv("train.csv")
rows <- sample(1:nrow(train), numTrain)
labels <- as.factor(train[rows,1])
train <- train[rows,-1]
rf <- randomForest(train, labels, xtest=test, ntree=numTrees)
predictions <- data.frame(ImageId=1:nrow(test), Label=levels(labels)[rf$test$predicted])
head(predictions)
write_csv(predictions, "randomforestsecond2")
# Creates a simple random forest benchmark
library(randomForest)
library(readr)
set.seed(0)
numTrain <- 10000
numTrees <- 50
train <- read_csv("test.csv")
test <- read_csv("train.csv")
rows <- sample(1:nrow(train), numTrain)
labels <- as.factor(train[rows,1])
train <- train[rows,-1]
rf <- randomForest(train, labels, xtest=test, ntree=numTrees)
predictions <- data.frame(ImageId=1:nrow(test), Label=levels(labels)[rf$test$predicted])
head(predictions)
write_csv(predictions[,11:12], "randomforestsecond3")
install.packages(c("manipulate", "Matrix"))
